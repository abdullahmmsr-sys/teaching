{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwCUw45mZKjG"
      },
      "source": [
        "Intro to NLP Practical<br>\n",
        "======================<br>\n",
        "Students will work through problems on n-grams, probabilities, OOV handling, and classifiers.<br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hJnSQ_vqZKjO"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2tr5e7WZKjQ"
      },
      "source": [
        "Toy corpus for language modeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0uJmCM0sZKjS"
      },
      "outputs": [],
      "source": [
        "corpus = [\n",
        "    \"Mary had a little lamb\",\n",
        "    \"Its fleece was white as snow\",\n",
        "    \"And everywhere that Mary went\",\n",
        "    \"The lamb was sure to go\"\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nIvCzEeZKjT"
      },
      "source": [
        "--- Part 1: Preprocessing ---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Re-DkrvQZKjU"
      },
      "source": [
        " Q1.1 Sequence notation<br>\n",
        "Exercise: Write sequence notation for the sentence:<br>\n",
        "\"Mary had a little lamb, its fleece was white as snow\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53ad5b2d",
        "outputId": "3f6c32d7-1f31-4be9-f1df-c0932e4a8ad7"
      },
      "source": [
        "sentence = \"Mary had a little lamb, its fleece was white as snow\"\n",
        "\n",
        "tokens = sentence.split()\n",
        "print(tokens)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Mary', 'had', 'a', 'little', 'lamb,', 'its', 'fleece', 'was', 'white', 'as', 'snow']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aKhi8cGTDAI4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAOpzABuZKjV"
      },
      "source": [
        " Q1.2 Add start/end tokens<br>\n",
        "Exercise: Write a function to tokenize the corpus and add <s>, </s>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "add_start_end = lambda sentence: [\"<s>\"] + sentence.split() + [\"</s>\"]\n",
        "\n",
        "tokenized_corpus = [add_start_end(sentence) for sentence in corpus]\n",
        "\n",
        "print(tokenized_corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qRM43VYEk64",
        "outputId": "6c9a9cfd-fa23-4bb7-84eb-266f39a4a389"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['<s>', 'Mary', 'had', 'a', 'little', 'lamb', '</s>'], ['<s>', 'Its', 'fleece', 'was', 'white', 'as', 'snow', '</s>'], ['<s>', 'And', 'everywhere', 'that', 'Mary', 'went', '</s>'], ['<s>', 'The', 'lamb', 'was', 'sure', 'to', 'go', '</s>']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRH1mpV5ZKjY"
      },
      "source": [
        "--- Part 2: N-grams & Probabilities ---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xVR2UlsZKjZ"
      },
      "source": [
        " Q2.1 Extract unigrams, bigrams, trigrams"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unigrams=[]\n",
        "bigrams=[]\n",
        "trigrams=[]\n",
        "\n",
        "for sentence in tokenized_corpus:\n",
        "    unigrams.extend(sentence)\n",
        "    bigrams.extend(list(zip(sentence[:-1], sentence[1:])))\n",
        "    trigrams.extend(list(zip(sentence[:-2], sentence[1:-1], sentence[2:])))\n",
        "\n",
        "print(unigrams)\n",
        "print(bigrams)\n",
        "print(trigrams)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9uQFOy4FzdL",
        "outputId": "1821e59f-7115-40e6-974f-8024d40a151e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<s>', 'Mary', 'had', 'a', 'little', 'lamb', '</s>', '<s>', 'Its', 'fleece', 'was', 'white', 'as', 'snow', '</s>', '<s>', 'And', 'everywhere', 'that', 'Mary', 'went', '</s>', '<s>', 'The', 'lamb', 'was', 'sure', 'to', 'go', '</s>']\n",
            "[('<s>', 'Mary'), ('Mary', 'had'), ('had', 'a'), ('a', 'little'), ('little', 'lamb'), ('lamb', '</s>'), ('<s>', 'Its'), ('Its', 'fleece'), ('fleece', 'was'), ('was', 'white'), ('white', 'as'), ('as', 'snow'), ('snow', '</s>'), ('<s>', 'And'), ('And', 'everywhere'), ('everywhere', 'that'), ('that', 'Mary'), ('Mary', 'went'), ('went', '</s>'), ('<s>', 'The'), ('The', 'lamb'), ('lamb', 'was'), ('was', 'sure'), ('sure', 'to'), ('to', 'go'), ('go', '</s>')]\n",
            "[('<s>', 'Mary', 'had'), ('Mary', 'had', 'a'), ('had', 'a', 'little'), ('a', 'little', 'lamb'), ('little', 'lamb', '</s>'), ('<s>', 'Its', 'fleece'), ('Its', 'fleece', 'was'), ('fleece', 'was', 'white'), ('was', 'white', 'as'), ('white', 'as', 'snow'), ('as', 'snow', '</s>'), ('<s>', 'And', 'everywhere'), ('And', 'everywhere', 'that'), ('everywhere', 'that', 'Mary'), ('that', 'Mary', 'went'), ('Mary', 'went', '</s>'), ('<s>', 'The', 'lamb'), ('The', 'lamb', 'was'), ('lamb', 'was', 'sure'), ('was', 'sure', 'to'), ('sure', 'to', 'go'), ('to', 'go', '</s>')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RuQzfXWZKjb"
      },
      "source": [
        " Q2.2 Bigram probabilities<br>\n",
        "Exercise: Write function to compute P(w_i | w_{i-1})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def bigram_probabilities(bigrams):\n",
        "    bigram_counts = Counter(bigrams)\n",
        "    unigram_counts = Counter(unigrams)\n",
        "    probabilities = {}\n",
        "    for bigram, count in bigram_counts.items():\n",
        "        word1, word2 = bigram\n",
        "        probabilities[bigram] = count / unigram_counts[word1]\n",
        "    return probabilities"
      ],
      "metadata": {
        "id": "wIGBEhTCGa1l"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3G1JGIAZKjj"
      },
      "source": [
        " Q2.3 Sentence probability<br>\n",
        "Exercise: Compute probability of \"Mary had a little lamb\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bigram_probs = bigram_probabilities(bigrams[:6])\n",
        "total_prob = 1\n",
        "for bigram, prob in bigram_probs.items():\n",
        "    print(f\"P({bigram[1]} | {bigram[0]}) = {prob}\")\n",
        "    total_prob *= prob\n",
        "\n",
        "print(\"total_prob = \" + str(total_prob))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duHE8FCJH05m",
        "outputId": "d81e7b67-c25b-427f-99ee-c8002e428856"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "P(Mary | <s>) = 0.25\n",
            "P(had | Mary) = 0.5\n",
            "P(a | had) = 1.0\n",
            "P(little | a) = 1.0\n",
            "P(lamb | little) = 1.0\n",
            "P(</s> | lamb) = 0.5\n",
            "total_prob = 0.0625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0unZilSZKjk"
      },
      "source": [
        "Q2.4 Handling OOV/UNK<br>\n",
        "Exercise: Replace unseen words with <UNK> and recompute\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def replace_unseen_words(corpus, vocab):\n",
        "    tokenized_corpus = []\n",
        "    for sentence in corpus:\n",
        "        tokenized_sentence = []\n",
        "        for word in sentence.split():\n",
        "            if word in vocab:\n",
        "                tokenized_sentence.append(word)\n",
        "            else:\n",
        "                tokenized_sentence.append(\"<UNK>\")\n",
        "        tokenized_corpus.append(tokenized_sentence)\n",
        "    return tokenized_corpus\n",
        "\n",
        "vocab = set(unigrams)\n",
        "example_corpus = [\"Mary had a little lamb\", \"Its fleece was black as snow\"]\n",
        "tokenized_corpus_with_unk = replace_unseen_words(example_corpus, vocab)\n",
        "print(tokenized_corpus_with_unk)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehND9cNnNLvy",
        "outputId": "85cb3f84-4ad7-48ca-89dc-20e35a116139"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['Mary', 'had', 'a', 'little', 'lamb'], ['Its', 'fleece', 'was', '<UNK>', 'as', 'snow']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evU5bff_ZKjl"
      },
      "source": [
        "--- Part 3: Classifier ---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3DxxnAKZKjm"
      },
      "source": [
        " Q3.1 Naive Bayes sentiment classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 📽 Exercise 3.1: Sentiment Classification on toy dataset\n",
        "\n",
        "In this exercise, you will build a simple sentiment classification model that predicts whether a given sentence is **positive** or **negative**.\n",
        "\n",
        "---\n",
        "\n",
        "## ✏️ Instructions:\n",
        "\n",
        "\n",
        "### 1️⃣ Perform Feature Extraction\n",
        "- Use **TF-IDF Vectorization** to convert names into numerical features.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "### 2️⃣ Train a Machine Learning Classifier\n",
        "- Use any classifier you are familiar with (e.g., **Logistic Regression** or **Naive Bayes**).\n",
        "- Split the data into **training** and **testing** sets.\n",
        "- Train the classifier on the training data.\n",
        "\n",
        "\n",
        "🚀 **Goal:** By the end of this exercise, you should be able to:\n",
        "- Apply **feature extraction** to text data.\n",
        "- Train and evaluate a **text classification model** using **machine learning**."
      ],
      "metadata": {
        "id": "Yyx3z1RL58el"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "s3fkQ5DUZKjm"
      },
      "outputs": [],
      "source": [
        "train_texts = [\n",
        "    \"I love my dog\",\n",
        "    \"This food is great\",\n",
        "    \"I hate waiting\",\n",
        "    \"The movie was boring\",\n",
        "    \"Happy with my phone\",\n",
        "    \"This is awful\"\n",
        "]\n",
        "train_labels = [\"pos\", \"pos\", \"neg\", \"neg\", \"pos\", \"neg\"]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report"
      ],
      "metadata": {
        "id": "eRGFyH5mR7tu"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf=TfidfVectorizer()\n",
        "train_features=tfidf.fit_transform(train_texts)\n",
        "tfidf_df=pd.DataFrame(train_features.toarray(),columns=tfidf.get_feature_names_out())\n",
        "tfidf_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "EpASWz9jSPNe",
        "outputId": "00dd77e2-7f47-49d1-f8e3-2a2fefaae741"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      awful  boring       dog      food     great     happy      hate  \\\n",
              "0  0.000000     0.0  0.611713  0.000000  0.000000  0.000000  0.000000   \n",
              "1  0.000000     0.0  0.000000  0.546779  0.546779  0.000000  0.000000   \n",
              "2  0.000000     0.0  0.000000  0.000000  0.000000  0.000000  0.707107   \n",
              "3  0.000000     0.5  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "4  0.000000     0.0  0.000000  0.000000  0.000000  0.521823  0.000000   \n",
              "5  0.653044     0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "\n",
              "         is      love  movie        my     phone  the      this   waiting  \\\n",
              "0  0.000000  0.611713    0.0  0.501613  0.000000  0.0  0.000000  0.000000   \n",
              "1  0.448367  0.000000    0.0  0.000000  0.000000  0.0  0.448367  0.000000   \n",
              "2  0.000000  0.000000    0.0  0.000000  0.000000  0.0  0.000000  0.707107   \n",
              "3  0.000000  0.000000    0.5  0.000000  0.000000  0.5  0.000000  0.000000   \n",
              "4  0.000000  0.000000    0.0  0.427903  0.521823  0.0  0.000000  0.000000   \n",
              "5  0.535506  0.000000    0.0  0.000000  0.000000  0.0  0.535506  0.000000   \n",
              "\n",
              "   was      with  \n",
              "0  0.0  0.000000  \n",
              "1  0.0  0.000000  \n",
              "2  0.0  0.000000  \n",
              "3  0.5  0.000000  \n",
              "4  0.0  0.521823  \n",
              "5  0.0  0.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b21cab10-fa28-4b4c-a917-05094235231d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>awful</th>\n",
              "      <th>boring</th>\n",
              "      <th>dog</th>\n",
              "      <th>food</th>\n",
              "      <th>great</th>\n",
              "      <th>happy</th>\n",
              "      <th>hate</th>\n",
              "      <th>is</th>\n",
              "      <th>love</th>\n",
              "      <th>movie</th>\n",
              "      <th>my</th>\n",
              "      <th>phone</th>\n",
              "      <th>the</th>\n",
              "      <th>this</th>\n",
              "      <th>waiting</th>\n",
              "      <th>was</th>\n",
              "      <th>with</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.611713</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.611713</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.501613</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.546779</td>\n",
              "      <td>0.546779</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.448367</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.448367</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.707107</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.707107</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.521823</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.427903</td>\n",
              "      <td>0.521823</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.521823</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.653044</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.535506</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.535506</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b21cab10-fa28-4b4c-a917-05094235231d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b21cab10-fa28-4b4c-a917-05094235231d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b21cab10-fa28-4b4c-a917-05094235231d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-05f02353-3bd3-4fd7-9039-bf738694e242\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-05f02353-3bd3-4fd7-9039-bf738694e242')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-05f02353-3bd3-4fd7-9039-bf738694e242 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_3bb778f1-7fe3-44a8-92a8-ac81711702a7\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('tfidf_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_3bb778f1-7fe3-44a8-92a8-ac81711702a7 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('tfidf_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "tfidf_df",
              "summary": "{\n  \"name\": \"tfidf_df\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"awful\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2666042859193406,\n        \"min\": 0.0,\n        \"max\": 0.6530444637414585,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.6530444637414585,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"boring\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2041241452319315,\n        \"min\": 0.0,\n        \"max\": 0.5,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.5,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dog\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.24973058640699738,\n        \"min\": 0.0,\n        \"max\": 0.6117125098631682,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0,\n          0.6117125098631682\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"food\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.22322161780824637,\n        \"min\": 0.0,\n        \"max\": 0.5467790631887662,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.5467790631887662,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"great\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.22322161780824637,\n        \"min\": 0.0,\n        \"max\": 0.5467790631887662,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.5467790631887662,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"happy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.21303354691013807,\n        \"min\": 0.0,\n        \"max\": 0.5218234880251023,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.5218234880251023,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2886751345948129,\n        \"min\": 0.0,\n        \"max\": 0.7071067811865476,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.7071067811865476,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"is\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2555249310866946,\n        \"min\": 0.0,\n        \"max\": 0.5355058021985527,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.0,\n          0.44836665359771705\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"love\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.24973058640699738,\n        \"min\": 0.0,\n        \"max\": 0.6117125098631682,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0,\n          0.6117125098631682\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"movie\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2041241452319315,\n        \"min\": 0.0,\n        \"max\": 0.5,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.5,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"my\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.24112919194870427,\n        \"min\": 0.0,\n        \"max\": 0.501613008756558,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.501613008756558,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"phone\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.21303354691013807,\n        \"min\": 0.0,\n        \"max\": 0.5218234880251023,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.5218234880251023,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"the\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2041241452319315,\n        \"min\": 0.0,\n        \"max\": 0.5,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.5,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"this\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2555249310866946,\n        \"min\": 0.0,\n        \"max\": 0.5355058021985527,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.0,\n          0.44836665359771705\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"waiting\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2886751345948129,\n        \"min\": 0.0,\n        \"max\": 0.7071067811865476,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.7071067811865476,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"was\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2041241452319315,\n        \"min\": 0.0,\n        \"max\": 0.5,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.5,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"with\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.21303354691013807,\n        \"min\": 0.0,\n        \"max\": 0.5218234880251023,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.5218234880251023,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vCTTGP7YUPqi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 📽 Exercise 3.2: Movie Review Classification using Movies Review Corpus\n",
        "\n",
        "In this exercise, you will build a simple text classification model that predicts whether a given **movie review** is **positive** or **negative** using the **NLTK Movie Reviews Corpus**.\n",
        "\n",
        "This is a classical example of text classification at the **sentence level**.\n",
        "\n",
        "---\n",
        "\n",
        "## ✏️ Instructions:\n",
        "\n",
        "### 1️⃣ Load the Data\n",
        "- Import the **Movie Reviews corpus** from **NLTK**.\n",
        "- Create a dataset where each example is a review and the label is either `'positive'` or `'negative'`.\n",
        "\n",
        "---\n",
        "\n",
        "### 2️⃣ Perform Feature Extraction\n",
        "- Use **TF-IDF Vectorization** to convert names into numerical features.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "### 3️⃣ Train a Machine Learning Classifier\n",
        "- Use any classifier you are familiar with (e.g., **Logistic Regression** or **Naive Bayes**).\n",
        "- Split the data into **training** and **testing** sets.\n",
        "- Train the classifier on the training data.\n",
        "\n",
        "---\n",
        "\n",
        "### 4️⃣ Evaluate the Classifier\n",
        "- Use **accuracy** and a **classification report** to evaluate your model on the test set.\n",
        "- Think about: How well does the model perform? Which reviews are harder to classify?\n",
        "\n",
        "---\n",
        "\n",
        "✅ You are free to explore:\n",
        "- Trying different classifiers.\n",
        "- Visualizing the results (e.g., confusion matrix).\n",
        "\n",
        "---\n",
        "\n",
        "🚀 **Goal:** By the end of this exercise, you should be able to:\n",
        "- Apply **feature extraction** to text data.\n",
        "- Train and evaluate a **text classification model** using **machine learning**."
      ],
      "metadata": {
        "id": "fq7Vj1ng1lw8"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVYgyaWtZKju"
      },
      "source": [
        " Q3.3 Discussion: Why bigrams vs unigrams?<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xv13VAlzZKju"
      },
      "source": [
        " Q3.4 Limitations of n-grams"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mIB4S3wZKju"
      },
      "source": [
        "--- Part 4: Wrap-up Reflection ---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzsTXZsTZKjv"
      },
      "source": [
        " Discussion Questions<br>\n",
        "1. Why do we need <UNK> tokens?<br>\n",
        "2. Why start/end tokens?<br>\n",
        "3. Why not always use higher n-grams?<br>\n",
        "4. How do classifiers differ from language models?"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}