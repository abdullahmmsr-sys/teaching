{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ankuj/teaching/blob/main/nlp_lab_day_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhE_ve2CMku1"
      },
      "source": [
        "\n",
        "<br>\n",
        "RNN Practical — Intro to Recurrent Neural Networks<br>\n",
        "Topics: Motivation, Basics, Architectures (One-to-Many, Many-to-One, etc.), Shared Parameters<br>\n",
        "Instructions: Complete each task by filling in the \"Your answer here\" sections.<br>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Eut5NBEdMku6"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def task_zero():\n"
      ],
      "metadata": {
        "id": "NiN_SjqWTxsg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzWjX89mMku-"
      },
      "source": [
        "------------------------------<br>\n",
        "Task 1: RNN Architectures <br>\n",
        "------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "xlDX2hiTMku-"
      },
      "outputs": [],
      "source": [
        "def task1_architectures():\n",
        "    \"\"\"\n",
        "    Identify the correct RNN architecture (One-to-One, One-to-Many, Many-to-One, Many-to-Many)\n",
        "    for the following scenarios:\n",
        "    a) Sentiment analysis of a sentence -> single label\n",
        "    b) Music generation from a single start token -> output sequence\n",
        "    c) Named entity recognition: tag each word in a sentence\n",
        "    d) Machine translation: source sentence -> target sentence\n",
        "    \"\"\"\n",
        "    # Your answer here:\n",
        "    # a) Many-to-One\n",
        "    # b) One-to-Many\n",
        "    # c) Many-to-Many\n",
        "    # d) Many-to-Many (encoder-decoder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fz1xbYovMkvA"
      },
      "source": [
        "------------------------------<br>\n",
        "Task 2: Shared Parameters <br>\n",
        "------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "5UlHXaMJMkvB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fc1c7ff-8106-42a2-9838-c4aef9386311"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input size (d): 4\n",
            "Hidden size (h): 3\n",
            "Number of parameters in W_xh: 12\n",
            "Number of parameters in W_hh: 9\n",
            "Number of parameters in b_h: 3\n",
            "Total number of shared parameters: 24\n"
          ]
        }
      ],
      "source": [
        "def task2_shared_parameters():\n",
        "    \"\"\"\n",
        "    Explain shared parameters in an RNN.\n",
        "    Compute parameter counts for an example:\n",
        "      input size d=4, hidden size h=3, sequence length T=10\n",
        "    \"\"\"\n",
        "    # Your answer here:\n",
        "\n",
        "    d = 4\n",
        "    h = 3\n",
        "    T = 10\n",
        "\n",
        "    num_params_Wxh = d * h\n",
        "    num_params_Whh = h * h\n",
        "    num_params_bh = h\n",
        "\n",
        "    total_params = num_params_Wxh + num_params_Whh + num_params_bh\n",
        "\n",
        "    print(f\"Input size (d): {d}\")\n",
        "    print(f\"Hidden size (h): {h}\")\n",
        "    print(f\"Number of parameters in W_xh: {num_params_Wxh}\")\n",
        "    print(f\"Number of parameters in W_hh: {num_params_Whh}\")\n",
        "    print(f\"Number of parameters in b_h: {num_params_bh}\")\n",
        "    print(f\"Total number of shared parameters: {total_params}\")\n",
        "\n",
        "task2_shared_parameters()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMyzZbkLMkvB"
      },
      "source": [
        "------------------------------<br>\n",
        "Task 3: Manual Forward Pass <br>\n",
        "------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "nlcGh9oLMkvC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "751c9615-2c39-4970-a5f2-4e33e4fe4cb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hidden state at time step 1: [ 0.46211716 -0.33637554]\n",
            "Hidden state at time step 2: [0.53994993 0.04027965]\n",
            "Hidden state at time step 3: [-0.21833125  0.19743869]\n"
          ]
        }
      ],
      "source": [
        "def task3_manual_forward_pass():\n",
        "    \"\"\"\n",
        "    Compute hidden states manually for a small RNN using np.tanh.\n",
        "    Input sequence length T=3, input size=2, hidden size=2\n",
        "    \"\"\"\n",
        "    x_seq = [np.array([0.5, -1.0]),\n",
        "             np.array([1.0, 0.0]),\n",
        "             np.array([-0.5, 0.5])]\n",
        "    h_prev = np.zeros(2)\n",
        "    W_xh = np.array([[0.6, -0.2],\n",
        "                     [0.1,  0.5]])\n",
        "    W_hh = np.array([[0.3, 0.4],\n",
        "                     [-0.2, 0.2]])\n",
        "    b_h = np.array([0.0,0.1])\n",
        "    h_list = []\n",
        "    for x in x_seq:\n",
        "        h_next = np.tanh(np.dot(W_xh, x) + np.dot(W_hh, h_prev) + b_h)\n",
        "        h_list.append(h_next)\n",
        "        h_prev = h_next\n",
        "\n",
        "    for i, h in enumerate(h_list):\n",
        "        print(f\"Hidden state at time step {i+1}: {h}\")\n",
        "\n",
        "task3_manual_forward_pass()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ORsqt1mMkvC"
      },
      "source": [
        "------------------------------<br>\n",
        "Task 4: NumPy RNN Cell Implementation <br>\n",
        "------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "lSsfHVNCMkvD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7892d4bf-da8b-4e35-e0d4-1c38089d64c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Toy Sequences:\n",
            "Sequence 1: [array([1. , 0.5]), array([0.2, 0.1]), array([ 0.3, -0.1])]\n",
            "Sequence 2: [array([-0.5, -0.4]), array([ 0.1, -0.2]), array([-0.3, -0.1])]\n",
            "Sequence 3: [array([0.8, 0.2]), array([0.5, 0.4]), array([0.1, 0.2])]\n",
            "Sequence 4: [array([-0.6, -0.2]), array([-0.4, -0.3]), array([ 0. , -0.1])]\n",
            "\n",
            "Labels: [1 0 1 0]\n",
            "\n",
            "Predictions: [np.int64(1), np.int64(0), np.int64(1), np.int64(0)]\n"
          ]
        }
      ],
      "source": [
        "def task4_numpy_rnn_cell():\n",
        "    \"\"\"\n",
        "    Implement a simple Many-to-One RNN in NumPy.\n",
        "    Use rnn_forward to compute h_T, then compute a readout: y = W_hy h_T + b_y\n",
        "    Predict class = argmax(y)\n",
        "    \"\"\"\n",
        "\n",
        "    # Toy dataset\n",
        "    toy_sequences = [\n",
        "        [np.array([1.0,0.5]), np.array([0.2,0.1]), np.array([0.3,-0.1])],\n",
        "        [np.array([-0.5,-0.4]), np.array([0.1,-0.2]), np.array([-0.3,-0.1])],\n",
        "        [np.array([0.8,0.2]), np.array([0.5,0.4]), np.array([0.1,0.2])],\n",
        "        [np.array([-0.6,-0.2]), np.array([-0.4,-0.3]), np.array([0.0,-0.1])]\n",
        "    ]\n",
        "    labels = np.array([1,0,1,0])\n",
        "\n",
        "\n",
        "    input_size = 2\n",
        "    hidden_size = 3\n",
        "    output_size = 2\n",
        "\n",
        "    W_xh = np.random.randn(hidden_size, input_size) * 0.01\n",
        "    W_hh = np.random.randn(hidden_size, hidden_size) * 0.01\n",
        "    b_h = np.zeros(hidden_size)\n",
        "    W_hy = np.random.randn(output_size, hidden_size) * 0.01\n",
        "    b_y = np.zeros(output_size)\n",
        "\n",
        "    def rnn_forward(sequence, h_prev, W_xh, W_hh, b_h):\n",
        "        h = h_prev\n",
        "        for x in sequence:\n",
        "            h = np.tanh(np.dot(W_xh, x) + np.dot(W_hh, h) + b_h)\n",
        "        return h\n",
        "\n",
        "    predictions = []\n",
        "    for seq in toy_sequences:\n",
        "        h_T = rnn_forward(seq, np.zeros(hidden_size), W_xh, W_hh, b_h)\n",
        "        y = np.dot(W_hy, h_T) + b_y\n",
        "        predicted_class = np.argmax(y)\n",
        "        predictions.append(predicted_class)\n",
        "\n",
        "    print(\"Toy Sequences:\")\n",
        "    for i, seq in enumerate(toy_sequences):\n",
        "        print(f\"Sequence {i+1}: {seq}\")\n",
        "    print(\"\\nLabels:\", labels)\n",
        "    print(\"\\nPredictions:\", predictions)\n",
        "\n",
        "task4_numpy_rnn_cell()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Goal:\n",
        "- Introduction to tensors in PyTorch\n",
        "- Build a simple RNN-based classifier\n",
        "\n",
        "Dataset:\n",
        "- We will classify short sequences of numbers as \"increasing\" or \"decreasing\"\n",
        "  Example:\n",
        "    [1, 2, 3, 4] → Label: 1 (increasing)\n",
        "    [5, 3, 1, 0] → Label: 0 (decreasing)\n",
        "\n",
        "----------------------------------------------------\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# ====================================================\n",
        "# STEP 1: Create a Tiny Synthetic Dataset\n",
        "# ====================================================\n",
        "\n",
        "def generate_data(num_samples=100, seq_len=4):\n",
        "    X = []\n",
        "    y = []\n",
        "    for _ in range(num_samples):\n",
        "        if torch.rand(1).item() > 0.5:\n",
        "            seq = torch.sort(torch.rand(seq_len))[0]   # Increasing\n",
        "            label = 1\n",
        "        else:\n",
        "            seq = torch.sort(torch.rand(seq_len), descending=True)[0]  # Decreasing\n",
        "            label = 0\n",
        "        X.append(seq.unsqueeze(-1))  # Shape: (seq_len, input_size=1)\n",
        "        y.append(label)\n",
        "    return torch.stack(X), torch.tensor(y)\n",
        "\n",
        "X, y = generate_data()\n",
        "# X shape → (batch_size=100, seq_len=4, input_size=1)\n",
        "# y shape → (batch_size=100)\n",
        "\n",
        "# ====================================================\n",
        "# STEP 2: Define a Simple RNN Classifier\n",
        "# ====================================================\n",
        "\n",
        "class RNNClassifier(nn.Module):\n",
        "    def __init__(self, input_size=1, hidden_size=8, num_classes=2):\n",
        "        super().__init__()\n",
        "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.size(0)\n",
        "        h0 = torch.zeros(1, batch_size, self.hidden_size)\n",
        "\n",
        "        output, hn = self.rnn(x, h0)\n",
        "        last_timestep_output = output[:, -1, :]\n",
        "        logits = self.fc(last_timestep_output)\n",
        "        return logits\n",
        "\n",
        "\n",
        "model = RNNClassifier()\n",
        "print(model)\n",
        "\n",
        "# ====================================================\n",
        "# STEP 3: Train the Model\n",
        "# ====================================================\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "for epoch in range(20):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(X)\n",
        "    loss = criterion(outputs, y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    print(f'Epoch [{epoch+1}/20], Loss: {loss.item():.4f}')\n",
        "\n",
        "\n",
        "\n",
        "# ====================================================\n",
        "# STEP 4: Test the Model on New Data\n",
        "# ====================================================\n",
        "\n",
        "test_X, test_y = generate_data(num_samples=10)\n",
        "with torch.no_grad():\n",
        "    test_outputs = model(test_X)\n",
        "    _, predicted = torch.max(test_outputs, 1)\n",
        "    accuracy = (predicted == test_y).sum().item() / len(test_y)\n",
        "    print(f'Test Accuracy: {accuracy * 100:.2f}%')\n",
        "\n",
        "print(\"\\nPredictions vs Actual:\")\n",
        "for i in range(len(test_X)):\n",
        "    print(f\"Sequence: {test_X[i].squeeze().tolist()}, Actual: {test_y[i].item()}, Predicted: {predicted[i].item()}\")"
      ],
      "metadata": {
        "id": "Nxyi_7bfR1vi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ad518db-72a5-449b-dc34-068c2c2ec308"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RNNClassifier(\n",
            "  (rnn): RNN(1, 8, batch_first=True)\n",
            "  (fc): Linear(in_features=8, out_features=2, bias=True)\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Epoch [1/20], Loss: 0.7020\n",
            "Epoch [2/20], Loss: 0.6912\n",
            "Epoch [3/20], Loss: 0.6848\n",
            "Epoch [4/20], Loss: 0.6800\n",
            "Epoch [5/20], Loss: 0.6749\n",
            "Epoch [6/20], Loss: 0.6690\n",
            "Epoch [7/20], Loss: 0.6619\n",
            "Epoch [8/20], Loss: 0.6539\n",
            "Epoch [9/20], Loss: 0.6452\n",
            "Epoch [10/20], Loss: 0.6362\n",
            "Epoch [11/20], Loss: 0.6273\n",
            "Epoch [12/20], Loss: 0.6182\n",
            "Epoch [13/20], Loss: 0.6081\n",
            "Epoch [14/20], Loss: 0.5961\n",
            "Epoch [15/20], Loss: 0.5817\n",
            "Epoch [16/20], Loss: 0.5650\n",
            "Epoch [17/20], Loss: 0.5461\n",
            "Epoch [18/20], Loss: 0.5250\n",
            "Epoch [19/20], Loss: 0.5020\n",
            "Epoch [20/20], Loss: 0.4768\n",
            "Test Accuracy: 100.00%\n",
            "\n",
            "Predictions vs Actual:\n",
            "Sequence: [0.03545117378234863, 0.3732271194458008, 0.4970362186431885, 0.598281741142273], Actual: 1, Predicted: 1\n",
            "Sequence: [0.22570812702178955, 0.4948967695236206, 0.8147835731506348, 0.8266753554344177], Actual: 1, Predicted: 1\n",
            "Sequence: [0.9910620450973511, 0.6495276093482971, 0.22582727670669556, 0.045015156269073486], Actual: 0, Predicted: 0\n",
            "Sequence: [0.09134173393249512, 0.2639707922935486, 0.5777094960212708, 0.6245934367179871], Actual: 1, Predicted: 1\n",
            "Sequence: [0.9947268962860107, 0.5697347521781921, 0.2881126403808594, 0.1758589744567871], Actual: 0, Predicted: 0\n",
            "Sequence: [0.4285848140716553, 0.5599063038825989, 0.7916487455368042, 0.9377102851867676], Actual: 1, Predicted: 1\n",
            "Sequence: [0.9142531156539917, 0.7651546001434326, 0.44606029987335205, 0.32307279109954834], Actual: 0, Predicted: 0\n",
            "Sequence: [0.555353045463562, 0.6006494760513306, 0.7672041654586792, 0.7893021106719971], Actual: 1, Predicted: 1\n",
            "Sequence: [0.2746591567993164, 0.3222838044166565, 0.4785163998603821, 0.7573444247245789], Actual: 1, Predicted: 1\n",
            "Sequence: [0.8924208879470825, 0.7713487148284912, 0.6537380218505859, 0.18415462970733643], Actual: 0, Predicted: 0\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}